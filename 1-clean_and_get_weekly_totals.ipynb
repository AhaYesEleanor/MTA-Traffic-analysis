{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from string import Template\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MTA_Apr_June_with_weeks.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#remove white space from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6590024</td>\n",
       "      <td>2232650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6590038</td>\n",
       "      <td>2232663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6590050</td>\n",
       "      <td>2232693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6590131</td>\n",
       "      <td>2232766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6590350</td>\n",
       "      <td>2232816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION        DATE      TIME  \\\n",
       "0  A002  R051  02-00-00   59 ST  NQR456W      BMT  04/21/2018  00:00:00   \n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT  04/21/2018  04:00:00   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT  04/21/2018  08:00:00   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT  04/21/2018  12:00:00   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT  04/21/2018  16:00:00   \n",
       "\n",
       "      DESC  ENTRIES    EXITS  WEEK  \n",
       "0  REGULAR  6590024  2232650     1  \n",
       "1  REGULAR  6590038  2232663     1  \n",
       "2  REGULAR  6590050  2232693     1  \n",
       "3  REGULAR  6590131  2232766     1  \n",
       "4  REGULAR  6590350  2232816     1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.columns = [column.strip() for column in data.columns]\n",
    "data.rename(columns={'week':'WEEK'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1970076 entries, 0 to 196689\n",
      "Data columns (total 12 columns):\n",
      "C/A         object\n",
      "UNIT        object\n",
      "SCP         object\n",
      "STATION     object\n",
      "LINENAME    object\n",
      "DIVISION    object\n",
      "DATE        object\n",
      "TIME        object\n",
      "DESC        object\n",
      "ENTRIES     int64\n",
      "EXITS       int64\n",
      "WEEK        int64\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 195.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509863, 12)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that's a lot of data! let's drop some observations off the bat. Getting rid of observations from 0:00 and 4:00, \n",
    "#    leaving only 12:00 pm-8:00 pm, when most tech-employees and potential donors might be commuting home or getting lunch\n",
    "data = data[data['TIME'].isin(('12:00:00','16:00:00', '20:00:00'))]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to calculate the difference between an observation's max and min values, which will mostly occur at 12:00 and 8:.\n",
    "#will be applied on unique turnstile_id + day-level\n",
    "def difference(srs):\n",
    "    return srs.max() - srs.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Identifying and grouping by unique turnstiles, taking the daily max-daily min for that turnstile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstile_col_names =['STATION','C/A','UNIT','SCP']\n",
    "\n",
    "by_turnstile_date =  data.groupby(by=turnstile_col_names+['WEEK']+['DATE'], as_index=False).agg(difference)\n",
    "by_turnstile_date['turnstile_id'] = by_turnstile_date.apply(lambda x: str(x['STATION']+'_'+x['C/A']+'_'+x['UNIT']+'_'+x['SCP']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.702130e+05\n",
       "mean     5.312254e+04\n",
       "std      8.530321e+06\n",
       "min      0.000000e+00\n",
       "25%      1.700000e+02\n",
       "50%      4.540000e+02\n",
       "75%      8.610000e+02\n",
       "max      1.953723e+09\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_turnstile_date['ENTRIES'].describe()\n",
    "#plt.hist(by_station_date['ENTRIES'][by_station_date['ENTRIES']>861])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#turnstiles with 1 really high day's entries probably are showing data anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRD CNTRL-42 ST_R238_R046_00-03-04     18\n",
       "59 ST COLUMBUS_N051_R084_02-00-01       2\n",
       "AVENUE H_B020_R263_00-03-01             1\n",
       "174-175 STS_N212_R253_01-06-01          1\n",
       "CASTLE HILL AV_R418_R106_00-03-00       1\n",
       "GREENPOINT AV_N405_R239_00-00-01        1\n",
       "182-183 STS_N215_R237_00-00-02          1\n",
       "DEKALB AV_H023_R236_00-06-01            1\n",
       "40 ST LOWERY ST_R518_R261_00-00-00      1\n",
       "30 AV_R513_R093_00-03-01                1\n",
       "FLUSHING-MAIN_R533_R055_00-03-07        1\n",
       "36 AV_R511_R091_00-00-00                1\n",
       "34 ST-PENN STA_N071_R013_00-06-00       1\n",
       "30 AV_R513_R093_00-03-02                1\n",
       "3 AV-149 ST_R311_R053_00-00-03          1\n",
       "174-175 STS_N212_R253_01-06-00          1\n",
       "LEXINGTON AV/53_N305A_R016_00-00-02     1\n",
       "GRD CNTRL-42 ST_R238_R046_00-00-00      1\n",
       "BROOKLYN BRIDGE_R210_R044_00-03-03      1\n",
       "149/GRAND CONC_R261_R205_00-00-01       1\n",
       "FORDHAM RD_R289_R119_00-03-00           1\n",
       "EASTN PKWY-MUSM_R621_R060_00-03-01      1\n",
       "167 ST_N206_R104_01-06-00               1\n",
       "BURNSIDE AV_R287_R244_00-05-00          1\n",
       "3 AV-149 ST_R311_R053_00-00-00          1\n",
       "PARK PLACE_R115_R029_00-06-00           1\n",
       "47-50 STS ROCK_N501_R020_01-06-01       1\n",
       "TIMES SQ-42 ST_R151_R033_00-00-07       1\n",
       "DEKALB AV_C008_R099_00-03-04            1\n",
       "ORCHARD BEACH_OB01_R459_00-00-02        1\n",
       "190 ST_N006A_R280_00-00-00              1\n",
       "183 ST_R288_R275_00-00-02               1\n",
       "WORLD TRADE CTR_N094_R029_01-00-01      1\n",
       "57 ST-7 AV_A010_R080_00-00-07           1\n",
       "Name: turnstile_id, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_turnstile_date[by_turnstile_date['ENTRIES']>5000].turnstile_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#identify outlier values of 'ENTRIES' for Station/Date pairs and replace them with weekly averages for the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'149/GRAND CONC': 1,\n",
       " '167 ST': 1,\n",
       " '174-175 STS': 1,\n",
       " '182-183 STS': 1,\n",
       " '183 ST': 1,\n",
       " '190 ST': 1,\n",
       " '3 AV-149 ST': 1,\n",
       " '30 AV': 1,\n",
       " '36 AV': 1,\n",
       " '40 ST LOWERY ST': 1,\n",
       " '57 ST-7 AV': 1,\n",
       " 'AVENUE H': 1,\n",
       " 'BROOKLYN BRIDGE': 1,\n",
       " 'BURNSIDE AV': 1,\n",
       " 'CASTLE HILL AV': 1,\n",
       " 'EASTN PKWY-MUSM': 1,\n",
       " 'FLUSHING-MAIN': 1,\n",
       " 'FORDHAM RD': 1,\n",
       " 'GREENPOINT AV': 1,\n",
       " 'PARK PLACE': 1,\n",
       " 'WORLD TRADE CTR': 1}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_turnstile_count = dict(by_turnstile_date[by_turnstile_date['ENTRIES']>5000].turnstile_id.value_counts())\n",
    "high_turnstile_count = {key : val for key,val in high_day_count.items() if val<2}\n",
    "high_turnstile_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.702130e+05\n",
       "mean     8.142840e+03\n",
       "std      1.218717e+06\n",
       "min      0.000000e+00\n",
       "25%      1.700000e+02\n",
       "50%      4.540000e+02\n",
       "75%      8.610000e+02\n",
       "max      2.791039e+08\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify outlier values of 'ENTRIES' for turnstile/Date pairs and replace them with weekly averages for the turnstile\n",
    "avg_turnstile_per_day = by_turnstile_date.groupby(by=['STATION','turnstile_id','WEEK'], as_index=False).mean().drop(columns='EXITS')\n",
    "avg_turnstile_per_day.rename(columns={'ENTRIES':'AVG_REPLACEMENT'}, inplace=True)\n",
    "\n",
    "by_turnstile_date_anomalies = by_turnstile_date[(by_turnstile_date['ENTRIES']>30000) & (by_turnstile_date['turnstile_id'].isin(high_turnstile_count.keys()))]\n",
    "by_turnstile_date_anomalies = by_turnstile_date_anomalies.merge(right=avg_turnstile_per_day, how='left')\n",
    "by_turnstile_date_anomalies['ENTRIES'] = by_turnstile_date_anomalies['AVG_REPLACEMENT']\n",
    "by_turnstile_date_anomalies.drop(columns=['AVG_REPLACEMENT'], inplace=True)\n",
    "\n",
    "by_turnstile_date = pd.concat([by_turnstile_date[(by_turnstile_date['ENTRIES']<=30000) | ~(by_turnstile_date['turnstile_id'].isin(high_turnstile_count.keys()))], by_turnstile_date_anomalies])\n",
    "\n",
    "by_turnstile_date.ENTRIES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.462800e+04\n",
       "mean     9.475097e+04\n",
       "std      4.910535e+06\n",
       "min      0.000000e+00\n",
       "25%      1.643750e+03\n",
       "50%      3.184500e+03\n",
       "75%      7.165500e+03\n",
       "max      4.581631e+08\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_date = by_turnstile_date.groupby(by=['STATION','WEEK', 'DATE'], as_index=False).sum()\n",
    "by_station_date.ENTRIES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34 ST-HERALD SQ    69\n",
       "34 ST-PENN STA     64\n",
       "TIMES SQ-42 ST     60\n",
       "59 ST COLUMBUS     51\n",
       "47-50 STS ROCK     50\n",
       "CHAMBERS ST        49\n",
       "23 ST              49\n",
       "59 ST              49\n",
       "GRD CNTRL-42 ST    49\n",
       "LEXINGTON AV/53    48\n",
       "42 ST-BRYANT PK    47\n",
       "50 ST              40\n",
       "86 ST              34\n",
       "JAY ST-METROTEC    21\n",
       "DEKALB AV           2\n",
       "WORLD TRADE CTR     1\n",
       "149/GRAND CONC      1\n",
       "183 ST              1\n",
       "PARK PLACE          1\n",
       "FLUSHING-MAIN       1\n",
       "57 ST-7 AV          1\n",
       "30 AV               1\n",
       "40 ST LOWERY ST     1\n",
       "36 AV               1\n",
       "BURNSIDE AV         1\n",
       "190 ST              1\n",
       "BROOKLYN BRIDGE     1\n",
       "AVENUE H            1\n",
       "FORDHAM RD          1\n",
       "EASTN PKWY-MUSM     1\n",
       "CASTLE HILL AV      1\n",
       "174-175 STS         1\n",
       "3 AV-149 ST         1\n",
       "GREENPOINT AV       1\n",
       "182-183 STS         1\n",
       "167 ST              1\n",
       "Name: STATION, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stations with 1 really high day's entries probably are showing data anomalies.\n",
    "by_station_date[by_station_date['ENTRIES']>30000].STATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'149/GRAND CONC': 1,\n",
       " '167 ST': 1,\n",
       " '174-175 STS': 1,\n",
       " '182-183 STS': 1,\n",
       " '183 ST': 1,\n",
       " '190 ST': 1,\n",
       " '3 AV-149 ST': 1,\n",
       " '30 AV': 1,\n",
       " '36 AV': 1,\n",
       " '40 ST LOWERY ST': 1,\n",
       " '57 ST-7 AV': 1,\n",
       " 'AVENUE H': 1,\n",
       " 'BROOKLYN BRIDGE': 1,\n",
       " 'BURNSIDE AV': 1,\n",
       " 'CASTLE HILL AV': 1,\n",
       " 'DEKALB AV': 2,\n",
       " 'EASTN PKWY-MUSM': 1,\n",
       " 'FLUSHING-MAIN': 1,\n",
       " 'FORDHAM RD': 1,\n",
       " 'GREENPOINT AV': 1,\n",
       " 'PARK PLACE': 1,\n",
       " 'WORLD TRADE CTR': 1}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify outlier values of 'ENTRIES' for Station/Date pairs and replace them with weekly averages for the station\n",
    "high_day_count = dict(by_station_date[by_station_date['ENTRIES']>30000].STATION.value_counts())\n",
    "high_day_count = {key : val for key,val in high_day_count.items() if val<=2}\n",
    "high_day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.462800e+04\n",
       "mean     2.095341e+04\n",
       "std      7.236803e+05\n",
       "min      0.000000e+00\n",
       "25%      1.643750e+03\n",
       "50%      3.184500e+03\n",
       "75%      7.165500e+03\n",
       "max      6.546071e+07\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify outlier values of 'ENTRIES' for Station/Date pairs and replace them with weekly averages for the station\n",
    "avg_day_per_week = by_station_date.groupby(by=['STATION','WEEK'], as_index=False).mean().drop(columns='EXITS')\n",
    "avg_day_per_week.rename(columns={'ENTRIES':'AVG_REPLACEMENT'}, inplace=True)\n",
    "\n",
    "by_station_date_anomalies = by_station_date[(by_station_date['ENTRIES']>30000) & (by_station_date['STATION'].isin(high_day_count.keys()))]\n",
    "by_station_date_anomalies = by_station_date_anomalies.merge(right=avg_day_per_week, how='left')\n",
    "by_station_date_anomalies['ENTRIES'] = by_station_date_anomalies['AVG_REPLACEMENT']\n",
    "by_station_date_anomalies.drop(columns=['AVG_REPLACEMENT'], inplace=True)\n",
    "\n",
    "by_station_date = pd.concat([by_station_date[(by_station_date['ENTRIES']<=30000) | ~(by_station_date['STATION'].isin(high_day_count.keys()))], by_station_date_anomalies])\n",
    "\n",
    "by_station_date.ENTRIES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>04/21/2018</td>\n",
       "      <td>10802.0</td>\n",
       "      <td>11866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>04/22/2018</td>\n",
       "      <td>8406.0</td>\n",
       "      <td>9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>04/23/2018</td>\n",
       "      <td>11463.0</td>\n",
       "      <td>10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>04/24/2018</td>\n",
       "      <td>11590.0</td>\n",
       "      <td>11111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>04/25/2018</td>\n",
       "      <td>11849.0</td>\n",
       "      <td>11164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION  WEEK        DATE  ENTRIES  EXITS\n",
       "0    1 AV     1  04/21/2018  10802.0  11866\n",
       "1    1 AV     1  04/22/2018   8406.0   9639\n",
       "2    1 AV     1  04/23/2018  11463.0  10550\n",
       "3    1 AV     1  04/24/2018  11590.0  11111\n",
       "4    1 AV     1  04/25/2018  11849.0  11164"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    2082\n",
       "6       6\n",
       "3       2\n",
       "5       1\n",
       "1       1\n",
       "4       1\n",
       "2       1\n",
       "Name: ENTRIES, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_date.groupby(by=['STATION','WEEK'], as_index=False).count().ENTRIES.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.462800e+04\n",
       "mean     2.095341e+04\n",
       "std      7.236803e+05\n",
       "min      0.000000e+00\n",
       "25%      1.643750e+03\n",
       "50%      3.184500e+03\n",
       "75%      7.165500e+03\n",
       "max      6.546071e+07\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_date.ENTRIES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('by_station_date_cleaned.pickle','wb') as f:\n",
    "    pickle.dump(by_station_date,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>ENTRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>1</td>\n",
       "      <td>78562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>2</td>\n",
       "      <td>79165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>3</td>\n",
       "      <td>77357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>4</td>\n",
       "      <td>76875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>5</td>\n",
       "      <td>79160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION  WEEK  ENTRIES\n",
       "0    1 AV     1  78562.0\n",
       "1    1 AV     2  79165.0\n",
       "2    1 AV     3  77357.0\n",
       "3    1 AV     4  76875.0\n",
       "4    1 AV     5  79160.0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_week =  by_station_date.groupby(by=['STATION', 'WEEK'], as_index=False).sum().drop(columns=['EXITS'])\n",
    "by_station_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.094000e+03\n",
       "mean     1.463737e+05\n",
       "std      1.912969e+06\n",
       "min      0.000000e+00\n",
       "25%      1.204325e+04\n",
       "50%      2.366850e+04\n",
       "75%      5.193025e+04\n",
       "max      6.552258e+07\n",
       "Name: ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_week.ENTRIES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>ENTRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>174-175 STS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.378611e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>182-183 STS</td>\n",
       "      <td>10</td>\n",
       "      <td>3.025962e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>183 ST</td>\n",
       "      <td>4</td>\n",
       "      <td>2.490976e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>190 ST</td>\n",
       "      <td>8</td>\n",
       "      <td>2.923168e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>3 AV-149 ST</td>\n",
       "      <td>7</td>\n",
       "      <td>6.552258e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>30 AV</td>\n",
       "      <td>9</td>\n",
       "      <td>2.007817e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>36 AV</td>\n",
       "      <td>9</td>\n",
       "      <td>1.379202e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>47-50 STS ROCK</td>\n",
       "      <td>4</td>\n",
       "      <td>2.186936e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>57 ST-7 AV</td>\n",
       "      <td>3</td>\n",
       "      <td>7.356971e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>BURNSIDE AV</td>\n",
       "      <td>1</td>\n",
       "      <td>2.416359e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>FORDHAM RD</td>\n",
       "      <td>1</td>\n",
       "      <td>2.257313e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>PARK PLACE</td>\n",
       "      <td>3</td>\n",
       "      <td>1.717405e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>TIMES SQ-42 ST</td>\n",
       "      <td>2</td>\n",
       "      <td>5.902509e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATION  WEEK       ENTRIES\n",
       "167      174-175 STS     8  1.378611e+06\n",
       "229      182-183 STS    10  3.025962e+07\n",
       "233           183 ST     4  2.490976e+07\n",
       "247           190 ST     8  2.923168e+07\n",
       "366      3 AV-149 ST     7  6.552258e+07\n",
       "370            30 AV     9  2.007817e+06\n",
       "412            36 AV     9  1.379202e+06\n",
       "487   47-50 STS ROCK     4  2.186936e+07\n",
       "566       57 ST-7 AV     3  7.356971e+05\n",
       "1067     BURNSIDE AV     1  2.416359e+06\n",
       "1327      FORDHAM RD     1  2.257313e+07\n",
       "1755      PARK PLACE     3  1.717405e+06\n",
       "1965  TIMES SQ-42 ST     2  5.902509e+05"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_station_week[by_station_week['ENTRIES']>500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of anomalously high weeks\n",
    "by_station_week = by_station_week[by_station_week['ENTRIES']<500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>mean_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>34 ST-HERALD SQ</td>\n",
       "      <td>466006.700000</td>\n",
       "      <td>4.504909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>TIMES SQ-42 ST</td>\n",
       "      <td>370798.555556</td>\n",
       "      <td>3.584527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>329103.500000</td>\n",
       "      <td>3.181459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23 ST</td>\n",
       "      <td>291405.100000</td>\n",
       "      <td>2.817027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>59 ST COLUMBUS</td>\n",
       "      <td>289903.300000</td>\n",
       "      <td>2.802509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>260665.200000</td>\n",
       "      <td>2.519863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>GRD CNTRL-42 ST</td>\n",
       "      <td>258111.400000</td>\n",
       "      <td>2.495175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>250260.400000</td>\n",
       "      <td>2.419279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>47-50 STS ROCK</td>\n",
       "      <td>247871.000000</td>\n",
       "      <td>2.396181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>86 ST</td>\n",
       "      <td>204099.200000</td>\n",
       "      <td>1.973037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATION        ENTRIES  mean_percentage\n",
       "39   34 ST-HERALD SQ  466006.700000         4.504909\n",
       "200   TIMES SQ-42 ST  370798.555556         3.584527\n",
       "41    34 ST-PENN STA  329103.500000         3.181459\n",
       "31             23 ST  291405.100000         2.817027\n",
       "60    59 ST COLUMBUS  289903.300000         2.802509\n",
       "59             59 ST  260665.200000         2.519863\n",
       "143  GRD CNTRL-42 ST  258111.400000         2.495175\n",
       "115      CHAMBERS ST  250260.400000         2.419279\n",
       "50    47-50 STS ROCK  247871.000000         2.396181\n",
       "74             86 ST  204099.200000         1.973037"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_avg_by_station = by_station_week.groupby(by=\"STATION\", as_index=False).mean().drop(columns=['WEEK'])\n",
    "weekly_avg_by_station[\"mean_percentage\"] = (weekly_avg_by_station[\"ENTRIES\"]/weekly_avg_by_station[\"ENTRIES\"].sum())*100\n",
    "weekly_avg_by_station = weekly_avg_by_station.sort_values(by='ENTRIES', ascending=False)\n",
    "weekly_avg_by_station.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('weekly_avg_by_station_clean.pickle', 'wb') as to_write:\n",
    "    pickle.dump(weekly_avg_by_station, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>mean_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>75148.3</td>\n",
       "      <td>0.726462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103 ST-CORONA</td>\n",
       "      <td>39958.6</td>\n",
       "      <td>0.386282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104 ST</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>0.068878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110 ST</td>\n",
       "      <td>32489.1</td>\n",
       "      <td>0.314074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111 ST</td>\n",
       "      <td>28965.5</td>\n",
       "      <td>0.280011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121 ST</td>\n",
       "      <td>2889.7</td>\n",
       "      <td>0.027935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>125 ST</td>\n",
       "      <td>122302.6</td>\n",
       "      <td>1.182305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>135 ST</td>\n",
       "      <td>40519.2</td>\n",
       "      <td>0.391701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>138/GRAND CONC</td>\n",
       "      <td>9103.9</td>\n",
       "      <td>0.088008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14 ST</td>\n",
       "      <td>146881.3</td>\n",
       "      <td>1.419908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATION   ENTRIES  mean_percentage\n",
       "0            1 AV   75148.3         0.726462\n",
       "1   103 ST-CORONA   39958.6         0.386282\n",
       "2          104 ST    7125.0         0.068878\n",
       "3          110 ST   32489.1         0.314074\n",
       "4          111 ST   28965.5         0.280011\n",
       "5          121 ST    2889.7         0.027935\n",
       "6          125 ST  122302.6         1.182305\n",
       "7          135 ST   40519.2         0.391701\n",
       "8  138/GRAND CONC    9103.9         0.088008\n",
       "9           14 ST  146881.3         1.419908"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_avg_by_station.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.693964807482622"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_avg_by_station.head(10).mean_percentage.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
